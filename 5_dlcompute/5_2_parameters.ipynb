{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\r\n",
    "X = torch.rand(size=(2, 4))\r\n",
    "net(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0679],\n",
       "        [0.0464]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(net[2].state_dict()) #通过索引访问任意层"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.1430,  0.3284,  0.3050,  0.2955,  0.1587,  0.2102, -0.2544, -0.0309]])), ('bias', tensor([0.0612]))])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(net[2].bias)\r\n",
    "print(net[2].bias.data)\r\n",
    "print(net[2].bias.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1416], requires_grad=True)\n",
      "tensor([0.1416])\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 一次性访问所有参数 列表推导式\r\n",
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\r\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])\r\n",
    "\r\n",
    "net.state_dict()['2.bias'].data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.1416])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 从嵌套块收集参数\r\n",
    "def block1():\r\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())\r\n",
    "\r\n",
    "def block2():\r\n",
    "    net = nn.Sequential()\r\n",
    "    for i in range(4):\r\n",
    "        # 在这里嵌套块进去，f字符串，主要是为了给每一层命名\r\n",
    "        net.add_module(f'block{i}', block1())\r\n",
    "    return net\r\n",
    "\r\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\r\n",
    "rgnet(X)\r\n",
    "\r\n",
    "print(rgnet)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "rgnet[0][1][0].bias.data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-9.3356e-02,  6.9690e-02,  1.6958e-04, -2.0502e-01,  4.5077e-01,\n",
       "        -3.0777e-02,  7.3256e-02,  2.2617e-01])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义初始化"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def init_normal(m):\r\n",
    "    if type(m) == nn.Linear:\r\n",
    "        nn.init.constant_(m.weight, 42)\r\n",
    "        nn.init.zeros_(m.bias)\r\n",
    "\r\n",
    "net[0].apply(init_normal)\r\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([42., 42., 42., 42.]), tensor(0.))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def my_init(m):\r\n",
    "    if type(m) == nn.Linear:\r\n",
    "        print(\r\n",
    "            'Init',\r\n",
    "            *[(name, params.shape) for name, params in m.named_parameters()][0]\r\n",
    "        )\r\n",
    "        nn.init.uniform_(m.weight, -10, 10)\r\n",
    "        m.weight.data += m.weight.data.abs() >= 5\r\n",
    "\r\n",
    "net.apply(my_init)\r\n",
    "net[0].weight"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.1388, -4.6200,  1.4865, -3.5567],\n",
       "        [ 9.6880,  1.5182,  0.7722,  7.4287],\n",
       "        [ 1.8368,  1.0540,  7.1372,  8.6445],\n",
       "        [ 6.8548, -1.4777, -4.8259,  0.1311],\n",
       "        [10.4066,  1.2817, -5.1404,  2.2318],\n",
       "        [ 1.5237,  2.1735, -4.5893,  2.2584],\n",
       "        [-1.9241,  3.0487,  1.5577, -8.2835],\n",
       "        [-5.0368,  6.5585, -4.4306,  8.2912]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 参数绑定（共享参数）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "shared = nn.Linear(8, 8)\r\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1))\r\n",
    "net(X)\r\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\r\n",
    "\r\n",
    "net[2].weight.data[0,0] = 150\r\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pytorch_gpu': conda)"
  },
  "interpreter": {
   "hash": "84b5a4a264b5f2401190ed1ffcbfa61bd7e26a5993c8ba59c52f05bbd4b966aa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}